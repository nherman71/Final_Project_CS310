{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T21:14:40.544337Z",
     "start_time": "2024-12-03T21:14:24.837857Z"
    }
   },
   "source": [
    "#load core libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.gen_dataset_ops import map_dataset\n",
    "\n",
    "#load the data once at the beginning to save time\n",
    "df = pd.read_parquet(\"hf://datasets/pcuenq/oxford-pets/data/train-00000-of-00001-ecc2afb43dedd5e0.parquet\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:14:41.670584Z",
     "start_time": "2024-12-03T21:14:41.642848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#get a sense of the data structure\n",
    "df.head()"
   ],
   "id": "c97ef8b7f6ad27bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                path  \\\n",
       "0  /data/datasets/magic-ml/oxford-iiit-pet/images...   \n",
       "1  /data/datasets/magic-ml/oxford-iiit-pet/images...   \n",
       "2  /data/datasets/magic-ml/oxford-iiit-pet/images...   \n",
       "3  /data/datasets/magic-ml/oxford-iiit-pet/images...   \n",
       "4  /data/datasets/magic-ml/oxford-iiit-pet/images...   \n",
       "\n",
       "                        label    dog  \\\n",
       "0                     Siamese  False   \n",
       "1                      Birman  False   \n",
       "2                   shiba inu   True   \n",
       "3  staffordshire bull terrier   True   \n",
       "4                basset hound   True   \n",
       "\n",
       "                                               image  \n",
       "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  \n",
       "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  \n",
       "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  \n",
       "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  \n",
       "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>dog</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/datasets/magic-ml/oxford-iiit-pet/images...</td>\n",
       "      <td>Siamese</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/datasets/magic-ml/oxford-iiit-pet/images...</td>\n",
       "      <td>Birman</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/datasets/magic-ml/oxford-iiit-pet/images...</td>\n",
       "      <td>shiba inu</td>\n",
       "      <td>True</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/datasets/magic-ml/oxford-iiit-pet/images...</td>\n",
       "      <td>staffordshire bull terrier</td>\n",
       "      <td>True</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/datasets/magic-ml/oxford-iiit-pet/images...</td>\n",
       "      <td>basset hound</td>\n",
       "      <td>True</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:46:32.848687Z",
     "start_time": "2024-12-03T21:46:27.452450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#making a python list from the series (column) in df\n",
    "images = [img['bytes'] for img in df[\"image\"]]\n",
    "is_dog = df['dog'].astype(int).values\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image_new = tf.image.decode_jpeg(image, channels=3)\n",
    "    #resize the image for the models input\n",
    "    image_new = tf.image.resize(image_new, IMG_SIZE)\n",
    "    #resize the image to be within the confines of tensors [-1,1]\n",
    "    image_new = image_new / 255.0\n",
    "    return image_new, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, is_dog))\n",
    "dataset = dataset.map(preprocess)\n",
    "\n",
    "print(dataset)"
   ],
   "id": "1b2e4e95c6de2cbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MapDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:48:50.171682Z",
     "start_time": "2024-12-03T21:46:41.917945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "training_size = 0.8\n",
    "#test size is not needed as we will take whatever is leftover after the split\n",
    "\n",
    "#split the dataset into subsets for training purposes\n",
    "split_tuple = tf.keras.utils.split_dataset(dataset = dataset, left_size = training_size, shuffle=True, seed=0)\n",
    "\n",
    "#having an error on line 6:\n",
    "#Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor).\n",
    "\n",
    "val_test_split = tf.keras.utils.split_dataset(dataset = split_tuple[0], left_size = 0.875, shuffle=False)\n",
    "train_dataset = val_test_split[0]\n",
    "validation_dataset = val_test_split[1]\n",
    "test_dataset = split_tuple[1]"
   ],
   "id": "caa17340bbcb5aff",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Everything Below is untested and in the works still",
   "id": "686ad51d202ba914"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:49:00.962562Z",
     "start_time": "2024-12-03T21:49:00.828539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ],
   "id": "2b4488f5b6d43b08",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:49:19.379207Z",
     "start_time": "2024-12-03T21:49:19.365094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DONT RUN FOR NOW\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "])\n",
    "for image, _ in train_dataset.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = image[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "        plt.imshow(augmented_image[0] / 255)\n",
    "        plt.axis('off')"
   ],
   "id": "b8149ac03ecba57d",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected '(' (3985758228.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[7], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    def data_augmentation = tf.keras.Sequential([\u001B[0m\n\u001B[1;37m                          ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m expected '('\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:50:59.954371Z",
     "start_time": "2024-12-03T21:50:58.386413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#load the base model\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ],
   "id": "fc599083b62d373a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:57:51.021254Z",
     "start_time": "2024-12-03T21:57:50.940724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=IMG_SHAPE)\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary(show_trainable=True)"
   ],
   "id": "e2f8055acf8399e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape         \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mTrai…\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_layer_3 (\u001B[38;5;33mInputLayer\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m3\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │   \u001B[1m-\u001B[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ mobilenetv2_1.00_224        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m1280\u001B[0m)    │  \u001B[38;5;34m2,257,984\u001B[0m │   \u001B[1;91mN\u001B[0m   │\n",
       "│ (\u001B[38;5;33mFunctional\u001B[0m)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ global_average_pooling2d    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1280\u001B[0m)          │          \u001B[38;5;34m0\u001B[0m │   \u001B[1m-\u001B[0m   │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)    │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1280\u001B[0m)          │          \u001B[38;5;34m0\u001B[0m │   \u001B[1m-\u001B[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)             │      \u001B[38;5;34m1,281\u001B[0m │   \u001B[1;38;5;34mY\u001B[0m   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ mobilenetv2_1.00_224        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ global_average_pooling2d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)    │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2,259,265\u001B[0m (8.62 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,259,265</span> (8.62 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,281\u001B[0m (5.00 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> (5.00 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m2,257,984\u001B[0m (8.61 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ],
   "id": "1f41bc04bb1a0a05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:55:04.083152Z",
     "start_time": "2024-12-03T21:55:04.025483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow import data as tf_data\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n",
    "validation_dataset = validation_dataset.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()"
   ],
   "id": "4f3a3489393b86e7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:48:49.730140Z",
     "start_time": "2024-12-03T23:46:17.322107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 2\n",
    "print(\"Fitting the top layer of the model\")\n",
    "model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)"
   ],
   "id": "adb804e9d4a6ad75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the top layer of the model\n",
      "Epoch 1/2\n",
      "\u001B[1m81/81\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m79s\u001B[0m 921ms/step - binary_accuracy: 0.9884 - loss: 0.0419 - val_binary_accuracy: 0.9882 - val_loss: 0.0384\n",
      "Epoch 2/2\n",
      "\u001B[1m81/81\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m73s\u001B[0m 905ms/step - binary_accuracy: 0.9906 - loss: 0.0283 - val_binary_accuracy: 0.9916 - val_loss: 0.0332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a0177a76d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:52:40.890994Z",
     "start_time": "2024-12-03T23:52:40.884620Z"
    }
   },
   "cell_type": "code",
   "source": "print(test_dataset)",
   "id": "4df8db433e3e4e1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CacheDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:54:17.377652Z",
     "start_time": "2024-12-03T23:54:16.762472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for images, labels in test_dataset.take(1):  # Limit to one batch for inspection\n",
    "    print(\"Labels (tf.int64 array):\", labels.numpy())"
   ],
   "id": "d1d7aafa131842e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels (tf.int64 array): [1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:57:57.196385Z",
     "start_time": "2024-12-03T23:56:49.704975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Test dataset evaluation, pre-fine tuning\")\n",
    "model.evaluate(test_dataset)\n",
    "model.evaluate(train_dataset)"
   ],
   "id": "87df0c459fc6a341",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset evaluation\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 519ms/step - binary_accuracy: 1.0000 - loss: 0.0237\n",
      "\u001B[1m81/81\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 809ms/step - binary_accuracy: 0.9933 - loss: 0.0203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01919730193912983, 0.9955538511276245]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:17:41.108046Z",
     "start_time": "2024-12-04T00:09:35.898980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model.trainable = True\n",
    "model.summary(show_trainable=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-7),  # Low learning rate\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 1\n",
    "print(\"Fitting the end-to-end model\")\n",
    "model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)"
   ],
   "id": "d3de1ef8f4bc16a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape         \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mTrai…\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_layer_3 (\u001B[38;5;33mInputLayer\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m3\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │   \u001B[1m-\u001B[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ mobilenetv2_1.00_224        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m1280\u001B[0m)    │  \u001B[38;5;34m2,257,984\u001B[0m │   \u001B[1;38;5;34mY\u001B[0m   │\n",
       "│ (\u001B[38;5;33mFunctional\u001B[0m)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ global_average_pooling2d    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1280\u001B[0m)          │          \u001B[38;5;34m0\u001B[0m │   \u001B[1m-\u001B[0m   │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)    │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1280\u001B[0m)          │          \u001B[38;5;34m0\u001B[0m │   \u001B[1m-\u001B[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)             │      \u001B[38;5;34m1,281\u001B[0m │   \u001B[1;38;5;34mY\u001B[0m   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ mobilenetv2_1.00_224        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ global_average_pooling2d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)    │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2,259,265\u001B[0m (8.62 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,259,265</span> (8.62 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m2,225,153\u001B[0m (8.49 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,225,153</span> (8.49 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m34,112\u001B[0m (133.25 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,112</span> (133.25 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the end-to-end model\n",
      "\u001B[1m81/81\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m485s\u001B[0m 6s/step - binary_accuracy: 0.9216 - loss: 0.2500 - val_binary_accuracy: 0.9747 - val_loss: 0.1029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a0227b3b10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:19:37.139182Z",
     "start_time": "2024-12-04T00:17:50.530716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Test dataset evaluation\")\n",
    "model.evaluate(test_dataset)\n",
    "model.evaluate(train_dataset)"
   ],
   "id": "5db794fdbec30173",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset evaluation\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 638ms/step - binary_accuracy: 0.9815 - loss: 0.0699\n",
      "\u001B[1m81/81\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m104s\u001B[0m 1s/step - binary_accuracy: 0.9880 - loss: 0.0423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04731040820479393, 0.9858882427215576]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
